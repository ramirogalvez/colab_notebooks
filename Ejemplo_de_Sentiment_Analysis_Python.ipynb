{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejemplo_de_Sentiment_Analysis_Python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramirogalvez/colab_notebooks/blob/master/Ejemplo_de_Sentiment_Analysis_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD4ITGavJJu_",
        "colab_type": "text"
      },
      "source": [
        "**Author**: Ramiro Gálvez (Twitter handle: [@RamiroHGalvez](https://twitter.com/RamiroHGalvez))\n",
        "\n",
        "**Date**: 2020-06-20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIq1jqnU_VHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKAyYEbb065l",
        "colab_type": "text"
      },
      "source": [
        "# ¿Qué tipos de análisis se pueden hacer programando?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_ajvGxNy4ao",
        "colab_type": "text"
      },
      "source": [
        "El objetivo de esta notebook es mostrarles un ejemplo del tipo de análisis avanzado que puede hacerse tras aprender a programar. Concretamente, en esta notebook se aborda un problema que ya vimos en clases: **analizar sentimiento en textos**.\n",
        "\n",
        "Para abordar este problema usaremos *Python*, un lenguage de programación de alto nivel ampliamente usado en *analytics*. *Python* es el lenguaje que se ve en MAAN II. Un lenguage alternativo, aunque principalmente orientado a Data Science, es *R*, que se ve en Intro a Data Science. Ambas son materias del **campo menor en tecnología y ciencias de datos.**\n",
        "\n",
        "Antes de pasar a trabajar con datos, veamos un concepto fundamental de programación que usaremos a lo largo de esta notebook: la declaración de funciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDJVB9frwG8w",
        "colab_type": "text"
      },
      "source": [
        "## Funciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4MQ2A1Q0Tpf",
        "colab_type": "text"
      },
      "source": [
        "En las próximas celdas de esta notebook veremos cómo se declaran y usan funciones en *Python*. El concepto de funciones es muy similar al de macros tal cual las venimos usando en MAAN I (con la diferencia de que pueden tomar parámetros de entrada y pueden devolver valores como output).\n",
        "\n",
        "A continuación, declararemos (crearemos) una función llamada \"*funcion_de_prueba*\" que toma como argumentos dos números, realiza operaciones con ellos, y devuelve el resultado obtenido tras realizar dichas operaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEMYRsxN2XMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def funcion_de_prueba(num1, num2):\n",
        "    \n",
        "    # Primera función de prueba\n",
        "    resultado_intermedio = min([num1, num2])\n",
        "    resultado_intermedio = 3 * resultado_intermedio\n",
        "    \n",
        "    return resultado_intermedio"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QloEOp963Ktb",
        "colab_type": "text"
      },
      "source": [
        "Una vez declarada la función, uno la puede usar sin problemas.\n",
        "Veamos ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-TFwMR23gg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e70ad50e-eee5-413b-b8cd-bdf1e05943e4"
      },
      "source": [
        "# Primer ejemplo\n",
        "print(funcion_de_prueba(1, 2))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDAwB2oxdTsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1217fe9f-59a8-4634-fad8-cf151ca38ae0"
      },
      "source": [
        "# Segundo ejemplo\n",
        "print(funcion_de_prueba(100, 2))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAdyKkz_dTaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7d0fe18-cffe-42a2-afbb-9da1c22c77bf"
      },
      "source": [
        "# Tercer ejemplo\n",
        "print(funcion_de_prueba(4, 4))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwlfclFV3suc",
        "colab_type": "text"
      },
      "source": [
        "En lo que resta de esta notebook usaremos funciones ya implementadas por nosotros o por gente que escribió librerías y las hizo públicas para que terceros las usen (igual a cuando en el editor de VBA activábamos funciones que nos permitían interactuar con *solver*).\n",
        "\n",
        "**IMPORTANTE**: la idea en esta clase no es que entiendan qué es lo que hace internamente cada función, sino que sepan que inputs toman y qué es lo que devuelven. Pero tengan presente que quienes estén interesados en estos temas pueden seguir aprendiéndolos dentro de la carrera de Economía Empresarial de UTDT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04brVX3j4968",
        "colab_type": "text"
      },
      "source": [
        "## Problema al que nos vamos a enfrentar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epDAajY_5oDF",
        "colab_type": "text"
      },
      "source": [
        "Nuestro objetivo será armar un sistema que \"lea\" un review/reseña de un restaurante y nos indique si la persona que escribió el review está hablando mal o no de del mismo (noten que este problema pueden aplicarse a otros dominios, e.g.: si se habla bien o mal de un político en Twitter, si se está haciendo un buen o mal review de un producto en Mercado Libre, etc.).\n",
        "\n",
        "Ya vimos en las clases iniciales de MAAN que esto puede hacerse con diccionarios de palabras (aunque también vimos que este enfoque es muy limitado). Ahora veremos cómo resolver el problema utilizando técnicas de inteligencia artificial! Concretamente, de aprendizaje automático/estadístico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN76_16Ie2uO",
        "colab_type": "text"
      },
      "source": [
        "Supongamos que tenemos \"datos\" como los siguientes:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5YL2Iuv9cci",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://drive.google.com/uc?id=1cZLBHwMJa34gMYjQbRve4qqwcb7xfkwN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LecmYGlqe-ls",
        "colab_type": "text"
      },
      "source": [
        "Lo que nosotros haremos será intentar aprender qué patrones (palabras en este caso) tienen los reviews que hablan mal del restaurante y qué patrones tienen los que no hablan mal.\n",
        "\n",
        "En vez de buscar esto de manera manual, utilizaremos un modelo de aprendizaje automático para aprender estos patrones a partir de los datos. Concretamente utilizaremos un modelo llamado **Random Forest**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV1nIjVowKR8",
        "colab_type": "text"
      },
      "source": [
        "## Datos que utilizaremos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LypliiLn94zx",
        "colab_type": "text"
      },
      "source": [
        "A continución trabajaremos con datos que se obtuvieron de uno de los portales más populares de reseñas de restaurantes del país. Generalmente, para obtener de manera masiva datos de este estilo se hace uso de *scrapers* (programas que tienen como objetivo recolectar datos de internet, que también se pueden programar usando *Python* con relativa facilidad  y que se cubren en MAAN II).\n",
        "\n",
        "La siguiente función carga 13174 reviews que previamente fueron recolectados y que están guardado en un archivo *.zip* en drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by07qwww4KMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def carga_datos_reviews(filepath):\n",
        "\n",
        "    # Descarga el archivo zip y lo descomprime en el server de Google\n",
        "    r = requests.get(filepath, stream=True)\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall()\n",
        "\n",
        "    # Carga los datos referidos al puntaje asignado\n",
        "    clase = pd.read_csv(\"./reviews/classificacion.txt\", sep = \"\\t\")\n",
        "\n",
        "    # Guarda el texto y el puntaje clase de cada review en una lista\n",
        "    review_data = []\n",
        "    for i, r in clase.iterrows():\n",
        "        fpath = \"./reviews/corpus/\" + r.id_comentario + \".txt\"\n",
        "        with open(fpath) as f:\n",
        "            review = f.read()\n",
        "        review_data.append({\"clase\": r.clase_comentario,\n",
        "                            \"review\": review})\n",
        "\n",
        "    return review_data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oPAGivSEiyy",
        "colab_type": "text"
      },
      "source": [
        "A continuación ejecutamos la función y cargamos los datos en memoria RAM (del server de Google)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYBJBe2GAE6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://drive.google.com/uc?id=1qR1hBSvzHJUeTumyhqF3CnhbzkCGPLhR\"\n",
        "reviews_data = carga_datos_reviews(url)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJtmZn6WErCX",
        "colab_type": "text"
      },
      "source": [
        "Exploremos un poco los datos!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtAPEViXAPRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82d314f0-2fc0-4e5d-94af-8496d08a1869"
      },
      "source": [
        "# Cantidad de reviews\n",
        "print(len(reviews_data))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KPS_3CzFb8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d672faf5-2257-4e48-9ca1-1118bba827c1"
      },
      "source": [
        "# Imprimamos la review en la posición 10\n",
        "print(reviews_data[10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'clase': 'Excelente', 'review': 'Muy lindo lugar, buena ambientacion, mesas bien separadas, para destacar la atencion de todo el personal. muy amables y atentos a cualquier requerimiento y por sobre todo excelentes las pastas'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_iLgy6JFi6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d9284f9-9e28-4c29-f612-cfc862f241fb"
      },
      "source": [
        "# Imprimamos el puntaje asignado al review en la posición 10\n",
        "print(reviews_data[10][\"clase\"])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Excelente\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUpxJ6l6FbqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "02ee5a3e-c70a-459d-c8d6-1129447343cc"
      },
      "source": [
        "# Imprimamos el texto escrito del review en la posición 10\n",
        "print(reviews_data[10][\"review\"])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Muy lindo lugar, buena ambientacion, mesas bien separadas, para destacar la atencion de todo el personal. muy amables y atentos a cualquier requerimiento y por sobre todo excelentes las pastas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkmr8a0vwPV7",
        "colab_type": "text"
      },
      "source": [
        "## Procesamiento de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZgujkCjFyCB",
        "colab_type": "text"
      },
      "source": [
        "Ahora nos enfocaremos en ver cómo podemos procesar los textos de cada review para que sea \"simple\" para una computadora aprender patrones a partir de los mismos (esto es un área gigante de estudio y existe toda una disciplina que se enfoca especialmente en estos temas, la misma se llama *procesamiento del lenguaje natural*).\n",
        "\n",
        "### Bags-of-words model (teoría)\n",
        "\n",
        "Para una computadora es difícil trabajar con el texto tal cuál nosotros leemos (por qué aun no tienen la capacidad de **entender** el mismo), pero le resulta muy simple trabajar con otras estructuras que conservan patrones de los textos.\n",
        "\n",
        "El camino que ahora seguiremos será procesar los textos de cada review de manera que conserven información relativa a qué escribió cada persona, pero que también permita a una computadora procesarlos de manera simple. Puntualmente, lo que haremos será representar los reviews/documentos de una manera análoga a como se muestra abajo (Fuente: [Jurafsky & Matrtin, 2000](https://web.stanford.edu/~jurafsky/slp3/))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khdl4VNmpvNg",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://drive.google.com/uc?id=1XOwP1TlFMcLRTf_XNX6H6PwFyrkfnSEV)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIDaE_HsqHxs",
        "colab_type": "text"
      },
      "source": [
        "A esta matriz se la conoce como *term-document matrix*. Lo que hace es simplemente contar cuántas veces aparece cada palabra en cada documento (en el caso de la figura, obras de Shakespeare, en el nuestro serán reviews). Noten que la matriz tendrá tantas filas como palabras distintas haya en los documentos y tantas columnas como documentos haya.\n",
        "\n",
        "Nosotros usaremos la traspuesta de esta matriz, conocida como *document-term matrix* (para mantener esa idea con la que venimos trabajando desde el comienzo de MAAN en que cada fila es una observación y cada columna hace referencia a una medición hecha a cada observación)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvn3jnyxy8X1",
        "colab_type": "text"
      },
      "source": [
        "### Bags-of-words model (implementación)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfQ5jLEfHeJC",
        "colab_type": "text"
      },
      "source": [
        "A continuación se presenta una función que toma como input los reviews cargados en memoría y devuelve dos objetos:\n",
        "\n",
        "1.   Una matriz (a la que internamente en la función llamamos X) en la cual cada fila representa un review, cada columna una palabra, y cada valor representa las apariciones de cada palabra en cada documento.\n",
        "2.   Un vector (a la que internamente en la función llamamos y) que indica para cada review si no fue malo (y=1) o si sí lo fue (y=0).\n",
        "\n",
        "A su vez, considera dos variantes sobre el modelo tradicional de bag-of-words:\n",
        "\n",
        "\n",
        "1.   Sólo conserva columnas para aquellas palabras que aparecen al menos *min_f* veces en el conjunto de todos los reviews (en donde *min_f* es un parámetro que se puede modificar).\n",
        "2.   Los valores internos están expresados en terminos relativos relativos a la suma de cada fila (algo que vimos cómo hacer en Pivot Tables). A modo de ejemplo, en un review dado un valor igual a 0.1 para la palabra *rico* (o la que fuera) indicaría que en ese review el 10% de las palabras escritas es *rico*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bBhxwebBlQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_bag_of_words(reviews_data, min_f):\n",
        "\n",
        "    # Expresión regular para tokenizar\n",
        "    regex = re.compile(\"\\w+\")\n",
        "\n",
        "    word_counter = {}\n",
        "    X_tmp = []\n",
        "    y = []\n",
        "\n",
        "    # Para cada review cuanto cuántas veces aparece cada palabra\n",
        "    for r in reviews_data:\n",
        "        tokens = regex.findall(r[\"review\"].lower())\n",
        "        for t in tokens:\n",
        "            word_counter[t] = word_counter.get(t, 0) + 1\n",
        "        X_tmp.append(dict(Counter(tokens)))\n",
        "        y.append(int(r[\"clase\"] != \"Malo\"))  # Aquí armo el vector y\n",
        "\n",
        "    # Identifico las palabras que aparecen al menos min_f veces\n",
        "    freq_tokens = set([e for e in word_counter if word_counter[e] >= min_f])\n",
        "\n",
        "    # Armo la matriz de bag-of-words con las modificaciones mencionadas\n",
        "    X = []\n",
        "    while X_tmp:\n",
        "        r = X_tmp.pop(0)\n",
        "        r = {e:r[e] for e in r if e in freq_tokens}\n",
        "        freq_tmp = sum(r.values())\n",
        "        X.append({t:(r[t]/freq_tmp) for t in r})\n",
        "        \n",
        "    X = pd.DataFrame(X, columns=freq_tokens).fillna(0.0)\n",
        "\n",
        "    return X, y\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5Q_yzE9y91e",
        "colab_type": "text"
      },
      "source": [
        "Ahora usemos esta función con los datos ya cargados en memoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-2d2QjfsAEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = to_bag_of_words(reviews_data, 5)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNlH_-QrzeRt",
        "colab_type": "text"
      },
      "source": [
        "Exploremos un poco X e y:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXY1L1N1JHlh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35ded2d4-01c9-49fb-892c-fef3e02344bb"
      },
      "source": [
        "# Veamos los primeros 20 valores de y\n",
        "print(y[:20])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2OiGptfmA-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70a32a6c-a53b-44f8-ede4-93161e02ab43"
      },
      "source": [
        "# Veamos qué porcentaje de los reviews no fueron malos\n",
        "print(sum(y)/len(y))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9045088811294975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oHsKJEzmArN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "ee9079af-cf94-4ff1-ea23-973b01fd95e3"
      },
      "source": [
        "# Veamos las primeras 5 filas de la matrix X\n",
        "X.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mucha</th>\n",
              "      <th>happy</th>\n",
              "      <th>torta</th>\n",
              "      <th>formal</th>\n",
              "      <th>justifican</th>\n",
              "      <th>area</th>\n",
              "      <th>comienza</th>\n",
              "      <th>baires</th>\n",
              "      <th>completos</th>\n",
              "      <th>tendrian</th>\n",
              "      <th>cae</th>\n",
              "      <th>historia</th>\n",
              "      <th>amex</th>\n",
              "      <th>osobuco</th>\n",
              "      <th>tazones</th>\n",
              "      <th>farmacia</th>\n",
              "      <th>solamente</th>\n",
              "      <th>trajeran</th>\n",
              "      <th>hierbas</th>\n",
              "      <th>camareras</th>\n",
              "      <th>higos</th>\n",
              "      <th>tuco</th>\n",
              "      <th>semi</th>\n",
              "      <th>hambre</th>\n",
              "      <th>verguenza</th>\n",
              "      <th>incluído</th>\n",
              "      <th>chicas</th>\n",
              "      <th>livings</th>\n",
              "      <th>incómodo</th>\n",
              "      <th>veces</th>\n",
              "      <th>almendras</th>\n",
              "      <th>atmósfera</th>\n",
              "      <th>corazón</th>\n",
              "      <th>suhi</th>\n",
              "      <th>delicada</th>\n",
              "      <th>familia</th>\n",
              "      <th>logra</th>\n",
              "      <th>13</th>\n",
              "      <th>fresquísimo</th>\n",
              "      <th>según</th>\n",
              "      <th>...</th>\n",
              "      <th>desagradable</th>\n",
              "      <th>sublimes</th>\n",
              "      <th>noto</th>\n",
              "      <th>azafran</th>\n",
              "      <th>malbec</th>\n",
              "      <th>cartelito</th>\n",
              "      <th>venir</th>\n",
              "      <th>molestos</th>\n",
              "      <th>restoran</th>\n",
              "      <th>publicados</th>\n",
              "      <th>tenemos</th>\n",
              "      <th>sentamos</th>\n",
              "      <th>rápida</th>\n",
              "      <th>cocidos</th>\n",
              "      <th>explicación</th>\n",
              "      <th>pocas</th>\n",
              "      <th>colocar</th>\n",
              "      <th>llevando</th>\n",
              "      <th>pannacotta</th>\n",
              "      <th>seguridad</th>\n",
              "      <th>ponerle</th>\n",
              "      <th>mayonesa</th>\n",
              "      <th>langostino</th>\n",
              "      <th>decidirse</th>\n",
              "      <th>cálida</th>\n",
              "      <th>equilibrado</th>\n",
              "      <th>sucios</th>\n",
              "      <th>entramos</th>\n",
              "      <th>quiero</th>\n",
              "      <th>durante</th>\n",
              "      <th>paltos</th>\n",
              "      <th>critica</th>\n",
              "      <th>mignon</th>\n",
              "      <th>web</th>\n",
              "      <th>consumir</th>\n",
              "      <th>paciente</th>\n",
              "      <th>abrir</th>\n",
              "      <th>preguntamos</th>\n",
              "      <th>brochettes</th>\n",
              "      <th>traigo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.02381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 6002 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   mucha  happy  torta  formal  ...  abrir  preguntamos  brochettes  traigo\n",
              "0    0.0    0.0    0.0     0.0  ...    0.0          0.0         0.0     0.0\n",
              "1    0.0    0.0    0.0     0.0  ...    0.0          0.0         0.0     0.0\n",
              "2    0.0    0.0    0.0     0.0  ...    0.0          0.0         0.0     0.0\n",
              "3    0.0    0.0    0.0     0.0  ...    0.0          0.0         0.0     0.0\n",
              "4    0.0    0.0    0.0     0.0  ...    0.0          0.0         0.0     0.0\n",
              "\n",
              "[5 rows x 6002 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-BbbTxL-dmD",
        "colab_type": "text"
      },
      "source": [
        "Ye expresamos los datos de una manera tal que pueden introducirse facilmente en modelos de aprendizaje automático! Ahora veamos un poquito de qué se tratan esto modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDVodx4twYIh",
        "colab_type": "text"
      },
      "source": [
        "## Modelo de aprendizaje automático"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajmYXRh3y-0h",
        "colab_type": "text"
      },
      "source": [
        "### Aprendizaje supervisado (mínima intuición)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvsC0OSGmrbY",
        "colab_type": "text"
      },
      "source": [
        "Cómo ya dijimos, en vez de buscar manera manual qué palabras o combinación de palabras aparecen en reviews malos y no malos, encontraremos estos patrones utilizando un modelo de aprendizaje automático. Esta idea cae dentro de lo que se conoce como **aprendizaje supervisado** (temas que ven en Intro a Data Science).\n",
        "\n",
        "A grandes rasgos, el esquema que siguen esta familia de modelos es el siguiente (Fuente: [Steinbach, Tan & Kumar, 2005](https://www-users.cs.umn.edu/~kumar001/dmbook/index.php)):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMOtTT2QsC2K",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://drive.google.com/uc?id=1U7192Mf2PF3Lkcu-MgziTejdRMofMATa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHn2dOogt5yj",
        "colab_type": "text"
      },
      "source": [
        "Nuestro equivalente al *Training Set* son la matriz X y el vector y, a partir de ellos un modelo aprenderá patrones relevantes para clasificar nuevos reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4cpiy2UzATC",
        "colab_type": "text"
      },
      "source": [
        "### Aprendizaje supervisado (en la práctica)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzNeMebSsB2H",
        "colab_type": "text"
      },
      "source": [
        "Lo siguiente función toma como input nuestra matriz X y nuesto vector y, y con ellos entrena un modelo conocido como Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "622LkJIbq0xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_learning_model(X, y):\n",
        "    clf = RandomForestClassifier(n_jobs=-1)\n",
        "    clf.fit(X, y)\n",
        "    clf.feature_names = list(X.columns.values)\n",
        "    return clf"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsdSUWjenDMM",
        "colab_type": "text"
      },
      "source": [
        "Ya tenemos los datos y propusimos un modelos, ahora **entrenemos** nuestro modelo!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wui6_sbWnIl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_analyzer = train_learning_model(X, y)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ef_MGUrnH2h",
        "colab_type": "text"
      },
      "source": [
        "Listo! Ya tenemos nuestro modelo entrenado. Ahora lo podemos usar para predecir qué dicen reviews que nunca vió."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2i1Go2xwgYS",
        "colab_type": "text"
      },
      "source": [
        "## Probemos cómo anda nuestro modelo en reviews nuevos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R0nc_h6uaM5",
        "colab_type": "text"
      },
      "source": [
        "La siguiente función toma input un review y un modelo entrenado, procesa el review para que tenga una estructura acorde a la matriz X y se la pasa al modelo entrenado para que prediga si es una review que está hablando bien o mal de un resturante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQEon64d080W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze_new_review(new_review, clf):\n",
        "\n",
        "    # Pasamos el review al formato de X\n",
        "    bow = dict(Counter(re.compile(\"\\w+\").findall(new_review.lower())))\n",
        "    bow = {e:bow[e] for e in bow if e in clf.feature_names}\n",
        "    sum_tokens = sum(bow.values())\n",
        "    bow = {e:(bow[e]/sum_tokens) for e in bow}\n",
        "    X_eval = pd.DataFrame([bow], columns = clf.feature_names).fillna(0)\n",
        "\n",
        "    # Predecimos utilizando nuestro modelos entrenado\n",
        "    prediction = clf.predict_proba(X_eval)[0, 1]\n",
        "\n",
        "    return \"Buen review :)\" if prediction > 0.9 else \"Mal review :(\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STGJZb9hnuuF",
        "colab_type": "text"
      },
      "source": [
        "Probemos con algunos ejemplos cómo anda nuestro sistema!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9qClAg5ANl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e3aad71-2079-4cbb-f230-b15a3a362d2f"
      },
      "source": [
        "new_review = \"\"\"Vine a cenar y me pedí las pastas con frutos de mar, primer\n",
        "                crítica te vienen 2 langostinos solos con algunas pocas cosas\n",
        "                más, le pedí si le podía agregar grama a las pastas, me avisaron\n",
        "                que tenía un costo adicional,pero nunca imaginé que ese costó\n",
        "                sería equivalente a un plato de pastas me cobraron $ 225 por un\n",
        "                poco de crema, ni siquiera era abundante, la verdad es un robo.\n",
        "                Lo único bueno es la atención de los mozos el resto un desastre\n",
        "                no vuelvo nunca más!!!!\"\"\"\n",
        "\n",
        "print(analyze_new_review(new_review, sentiment_analyzer))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mal review :(\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXFUUhJi5kTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84531670-fb10-4640-8ae1-8cdb4f418577"
      },
      "source": [
        "new_review = \"\"\"Buenísimo! Pedí en cuarentena y todo super bien.\n",
        "                Las quesadillas de lomo y pollo geniales, abundantes y muy\n",
        "                ricas. Las papas con cheddar muy buenas tambien! Recomiendo!\"\"\"\n",
        "\n",
        "print(analyze_new_review(new_review, sentiment_analyzer))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Buen review :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIQBfUmE8doW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abd755a2-5689-4f82-c8ae-251dad7bc102"
      },
      "source": [
        "new_review = \"\"\"La atención es pésima. Los mozos y mozas no prestan atención a\n",
        "                nada. Tardaron 30 minutos en traerme la carta y 25 minutos en\n",
        "                traerme la cuenta. No están capacitados para atender gente\n",
        "                tienen pésimos modales y todos cara de ORTO. No vuelvo más\"\"\"\n",
        "\n",
        "print(analyze_new_review(new_review, sentiment_analyzer))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mal review :(\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dN1z56K7Fgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "714c33dc-44f1-4f22-b296-b8b9da9b1fa4"
      },
      "source": [
        "new_review = \"\"\"En plena cuarentena, el Locro que hicieron para el 1ro. de Mayo\n",
        "                espectacular, bien completo y generoso a muy buen precio!!!\n",
        "                Los felicito y esperamos el del 25!!! A no aflojar y ayudar a\n",
        "                los bodegones de barrio!!\"\"\"\n",
        "\n",
        "print(analyze_new_review(new_review, sentiment_analyzer))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Buen review :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jpqj0Au_ATk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6bd0f6f-0ed1-4dcf-f81d-38f51da87121"
      },
      "source": [
        "new_review = \"\"\"LLAMO POR UN PEDIDO DE HACE DOS HORAS QUE ESTOY ESPERANDO Y NADIE\n",
        "                SABE NADA, VUELVO Y LLAMO Y ME DICEN QUE TIENEN DEMORA DE\n",
        "                30minutos, OSEA DOS HORAS Y MEDIAS. Y CUANDO LLEGA ES UNA REAL\n",
        "                PORGONA TODO, LA VERDAD COMO SE NOTA QUE ESTAN INDRUSTIALIZADOS\n",
        "                Y NO LES IMPORTA PERDER CLIENTES, PERO LO QUE NO SABEN ES QUE EL\n",
        "                BOCA A BOCA ES LO PEOR Y TARDE O TEMPRANO VAN A CAER\"\"\"\n",
        "\n",
        "print(analyze_new_review(new_review, sentiment_analyzer))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mal review :(\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DWX-ROUMQ29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f35d19cd-8696-478d-bee9-120f16253c3b"
      },
      "source": [
        "new_review = \"\"\"Hace varios años que voy a este local y me gusta todo en\n",
        "                general. Buena atención de parte de los chicos y chicas que\n",
        "                trabajan. Muy limpio.\"\"\"\n",
        "\n",
        "print(analyze_new_review(new_review, sentiment_analyzer))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Buen review :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSwzPKwV0LGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eed3d71e-1d1a-4704-dd79-459bd5b535dd"
      },
      "source": [
        "new_review = \"\"\"Hay un solo pibe en el café que te toma el pedido, te cobra, lo\n",
        "                prepara, levanta y limpia las mesas y también lava las tazas\n",
        "                sucias.  Dejen de explotar adolescentes! En promedio 30 minutos\n",
        "                de espera por un café con leche...\"\"\"\n",
        "\n",
        "print(analyze_new_review(new_review, sentiment_analyzer))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mal review :(\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCSDcabtQOXa",
        "colab_type": "text"
      },
      "source": [
        "Anda bastante bien!\n",
        "\n",
        "Ahora prueben ustedes escribir reviews inventados (o sacados de algún portal online). ¿Pueden escribir reviews para los que el sistema ande mal?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEO_UsVkzllK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Escriban un review inventado por ustedes y prueben qué predice el modelo\n",
        "\n",
        "my_review = \"\"\"ESCRIBAN UN REVIEW\"\"\"\n",
        "\n",
        "print(analyze_new_review(my_review, sentiment_analyzer))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}